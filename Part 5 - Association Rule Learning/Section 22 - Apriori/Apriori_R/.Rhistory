distance = read_csv("./gpa.csv")
library(tidyverse)
distance = read_csv("./gpa.csv")
distance = read_csv("./gpa.csv")
setwd("~/Desktop/机器学习Udemy/Machine Learning A-Z Chinese Template Folder/Part 4 - Clustering/Section 19 - K-Means Clustering")
#K-Means Clustering
#Importing the DataSet
dataset = read.csv("Mall_Customers.csv")
View(dataset)
#Importing the DataSet
dataset = read.csv("Mall_Customers.csv")
X = dataset[4:5]
#Using the Elbow Method to find the optimal number of clusters
set.seed(6)
mcss = vector()
for (i in 1:10) mcss[i] = kmeans(X,i)$tot.withinss
mcsss
mcss
mcss[3]
plot(1:10,
mcss,
type = 'b',
main = 'The Albow Method',
xlab = 'Number of Clusters',
ylab = 'mcss')
#K-Means Clustering
#Importing the DataSet
dataset = read.csv("Mall_Customers.csv")
X = dataset[4:5]
#Using the Elbow Method to find the optimal number of clusters
set.seed(29)
mcss = vector()
for (i in 1:10) mcss[i] = kmeans(X,i)$tot.withinss
plot(1:10,
mcss,
type = 'b',
main = 'The Albow Method',
xlab = 'Number of Clusters',
ylab = 'mcss')
#As we can see from the plot, the elbow point is 5
#Fitting the K-Means to the dataset
#K-Means Clustering
#Importing the DataSet
dataset = read.csv("Mall_Customers.csv")
X = dataset[4:5]
#Using the Elbow Method to find the optimal number of clusters
set.seed(6)
mcss = vector()
for (i in 1:10) mcss[i] = kmeans(X,i)$tot.withinss
plot(1:10,
mcss,
type = 'b',
main = 'The Albow Method',
xlab = 'Number of Clusters',
ylab = 'mcss')
#As we can see from the plot, the elbow point is 5
#Fitting the K-Means to the dataset
#Fitting the K-Means to the dataset
Kmeans = kmeans(X, 5, iter.max = 300, nstart = 10)
y_Kmeans = kmeans$cluster
View(Kmeans)
y_Kmeans = Kmeans$cluster
library("cluster", lib.loc="/Library/Frameworks/R.framework/Versions/3.5/Resources/library")
#Visualizing the Clusters
#library('cluster')
clusplot(X,
y_Kmeans,
main = 'K-Means Clusters',
lines = 0,
shade = TRUE,
color = TRUE,
labels = 2,
#每个cluster是不是表示方式一样
plotchar = FALSE,
span = TRUE,
xlab = 'Annual Income',
ylab = 'Shopping Score')
x
X
setwd("~/Desktop/机器学习Udemy/Machine Learning A-Z Chinese Template Folder/Part 5 - Association Rule Learning/Section 22 - Apriori/Apriori_R")
#Apriori
#read data from the dataset
dataset = read.csv('Market_Basket_Optimisation.csv')
#Apriori
#read data from the dataset
dataset = read.csv('Market_Basket_Optimisation.csv')
View(dataset)
install.packages('erules')
#read data from the dataset
install.packages('arules')
#Apriori
#read data from the dataset
install.packages('arules')
library('arules')
dataset = read.csv('Market_Basket_Optimisation.csv')
dataset = read.transactions("Market_Basket_Optimisation.csv", sep = ',', rm.duplicates = TRUE)
summary(dataset)
##稀疏矩阵，density是1在0里面的
itemFrequencyPlot(dataset, topN = 100)
##稀疏矩阵，density是1在0里面的
itemFrequencyPlot(dataset, topN = 10)
# Training Apriori on our dataset
# Step 1: decide the minimum support and minimum confidence
# Minimum Support: be sold at least 3 times a day - 3*7/7500
# Confidence: not itensial, will test and find out - 0.8(default)
rules = apriori(data = dataset, parameter = list(support=0.003, confidence=0.8))
# Training Apriori on our dataset
# Step 1: decide the minimum support and minimum confidence
# Minimum Support: be sold at least 3 times a day - 3*7/7500
# Confidence: not itensial, will test and find out - 0.8(default)
rules = apriori(data = dataset, parameter = list(support=0.003, confidence=0.4))
# Visualizing the results(rules)
inspect(sort(rules, by = 'lift')[1:10])
# Confidence: not itensial, will test and find out - 0.8(default)
rules = apriori(data = dataset, parameter = list(support=0.003, confidence=0.2))
# if little rules found, means confidence is too high!
# Visualizing the results(rules)
inspect(sort(rules, by = 'lift')[1:10])
#Apriori
# Look at the data itself
#read data from the dataset （from French）
#install.packages('arules')
library('arules')
dataset = read.csv('Market_Basket_Optimisation.csv', header = FALSE)
dataset = read.transactions("Market_Basket_Optimisation.csv", sep = ',', rm.duplicates = TRUE)
summary(dataset)
##稀疏矩阵，density是1在0里面的
itemFrequencyPlot(dataset, topN = 10)
# Training Apriori on our dataset
# Step 1: decide the minimum support and minimum confidence
# Minimum Support: be sold at least 3 times a day - 3*7/7500
# Confidence: not itensial, will test and find out - 0.8(default)
rules = apriori(data = dataset, parameter = list(support=0.004, confidence=0.2))
# if little rules found, means confidence is too high!
# Visualizing the results(rules)
inspect(sort(rules, by = 'lift')[1:10])
